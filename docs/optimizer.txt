
.. _optimizer:

Local Optimizers
================

TSASE holds the following local optimization routines:

Local Optimization
------------------

   The local optimization algorithms available in TSASE are: SDLBFGS and MDmin

   All local optimization classes have the following structure: 
	
   .. code-block:: none
	
	class Optimizer:
		def __init__(self, atoms, restart=None, logfile=None):
		def run(self, fmax=0.05, emax= 0.001, steps=1000000,optimizer='L2',maximize=False):
		def get_number_of_steps():
    
   The structure of the local optimization classes is very similar to ASE implementation 
   with a few additional features. Below describes the additional options in TSASE implementation:
 
   	**optimizer** : In ASEs implementation the convergence criteria is only the maximum per atom force
			In TSASE implementation there are additional options:
				
				**'L2'** : L2-norm for the entire force vector
				
				**'maxatom'** : maximum per atom force
				
				**'energy'** :  value of potential energy 
				
				**'bgsd'** : a special case convergence criteria for the bgsd saddle search;
					     a trajectory is converged when the L2 norm of the force or the 
					     potential energy is below a specified value 
	
	**fmax** : specified force convergence criteria
	
	**emax** : specified energy convergence criteria 
	 
	

Steepest Descent Limited memory BFGS
------------------------------------

    A limited memory version of the bfgs algorithm. Unlike the bfgs algorithm
    used in bfgs.py, the inverse of Hessian matrix is updated.  The inverse
    Hessian is represented only as a diagonal matrix to save memor.y

    This version of LBFGS is based off of ASE implementation with a few improvements. 
    The initial guess for the inverse Hessian is updated at every step by estimating the 
    curvature along the previous step direction.  If a negative curvature is calculated or 
    if the angle between the force and the LBFGS direction is greater than 90, then the 
    memory is reset.

    Below is an example script of how to use this optimizer: 
 
    .. code-block:: none
	
	al = tsase.calculators.al()
	p = tsase.io.read_con('al.con')
	p.set_calculator(al)
	min = tsase.optimize.SDLBFGS(p, maxstep=0.1, memory=100)
	min.run() 

MDMin
-----
    
    ASE implementation of MDMin `(See ASE for details) <https://wiki.fysik.dtu.dk/ase/ase/optimize.html>`_ with the additional option to have a maxmimum step distance. 

    Below is and example of how to use this optimizer

    .. code-block:: none
	
	min = tsase.optimize.MDMin(p,dt=0.1,maxstep=1.0)
	min.run() 

- **MushyBox**

   Relaxes a variable number of degrees of freedom which may include full cell relaxation

Global Optimizers
==================

TSASE holds the following global optimization routines:

Basin Hopping
-------------
    Below outlines the features of the basin hoppping implementation. 

    class ``tsase.optimizer.`` **BasinHopping** (self, atoms, temperature=100 * kB, optimizer=SDLBFGS, fmax=0.1,dr=0.1, adjust_cm=True, mss=0.2, minenergy=None, distribution='uniform', significant_structure = False, pushapart = 0.4,jumpmax=15,adjust_step_size=None, adjust_every = None, target_ratio = 0.5, adjust_fraction = 0.05)

    **atoms** : atoms object defining the PES

    **temperature** : temperature in kT

    **optimizer** : local optimizer 
    
    **fmax** : magnitude of the L2 norm used as the convergence criteria for local optimization

    **dr** : maximum displacement in each degree of freedom for Monte Carlo trial moves

    **adjust_cm** : fix the center of mass

    **mss** : maximum stepsize for the local optimization

    **minenergy** : the BH algorithm stops when a configuration if found with a lower potential energy than this value

    **distribution** : the distribution used for the displacement of each atom 
        
        default: uniform

        options: 'gaussian': the parameter dr serves as the standard deviation of the gaussian distribution

                 'uniform': a uniform random number is selected in the interval [-dr,dr]

                 'linear': a uniform random number is selected in the interval [-dr*d,dr*d] where d is the distance from the geometric center of a cluster

                 'quadratic': a uniform random number is selected in the interval [-dr*d*d,dr*d*d] where d is the distance from the geometric center of a cluster
                  
    **significant_structure** : displace from the optimized structures 

    **pushapart** : push atoms apart until all atoms are no closer than this distance 

    **jumpmax** : after this number of consecutive rejected jumps, accept the following move.  This allows for a more global search of the potential energy surface.  

    **adjust_step_size**: adjust the step size so that a target_ratio of steps are accepted

    **adjust_every**: adjust step size after this many Monte Carlo steps

    **target_ratio**: specified ratio of accepted steps

    **adjust_fraction**: the fraction by which to change the step size in order to meet the target acceptance ratio


Minima Hopping
--------------
    Below outlines the features of the minima hoppping implementation.

    class ``tsase.optimizer.``  **MinimaHopping**(self, atoms, T0, beta1, beta2, beta3, Ediff0, alpha1, alpha2, mdmin, logfile, minima_threshold, timestep, optimizer, minima_traj, fmax, dimer_a, dimer_d, dimer_steps)
    
    **atoms** : atoms object defining the PES

.. rubric:: References
.. [#Wales97_5111] D. J. Wales, J. P. K. Doye, "Global Optimization by Basin-Hopping and the Lowest Energy Structures of Lennard-Jones Clusters Containing up to 110 Atoms", *J. Phys. Chem.* **101**,5111-5116 (1997).
.. [#Goedecker04_9911] S. Goedecker, "Minima hopping: An efficient search method for the global minimum of the potential energy surface of complex molecular systems", *J. Chem. Phys.* **120**, 9911 (2004).

